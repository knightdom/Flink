# Flink学习笔记

## 1. 系统架构

![image-20220909164739537](/Users/edgar/Documents/www/Flink/markdown-images/image-20220909164739537.png)

### 1.1 作业管理器(JobManager)

控制一个应用程序执行的主进程，是Flink集群中任务管理和调度的核心。

每个应用程序有且仅有一个JobManager正在运行。

#### 1.1.1 Jobmaster

- JobMaster是JobManager中最核心的组件，负责处理**单独**的作业(Job)
- JobMaster工作流程
  1. 客户端接收需要执行的应用（例如，Jar包）
  2. 由客户端将应用分析，获得：Jar包、数据流图(dataflow graph)、作业图(JobGraph)，并提交给JobMaster
  3. JobMaster将JobGraph转换成一个物理层面的数据流图-执行图(ExecutionGraph)，它包含了所有可以并发执行的任务。
  4. JobMaster向资源管理器(ResourceManager)发出请求，申请执行任务的必要资源
  5. 获得足够的资源后，JobMaster就将ExecutionGraph分发到真正运行的TaskManager
  6. 在运行过程中，JobMaster会负责所有需要中央协调的操作，例如检查点(checkpoints)的协调

#### 1.1.2 资源管理器(ResourceManager)

- 负责资源的分配和管理
- 在Flink集群中只有一个
- “资源”，TaskManager中的任务槽(task slots)。任务槽就是集群中的资源调配单元，包括执行计算的一组CPU和内存资源。
- 每个任务(Task)都需要分配到一个slot上执行

#### 1.1.3 分发器(Dispatcher)

- 负责提供一个REST接口，用来提交应用，并负责为每个新提交的作业启动一个新的JobMaster组件
- 启动一个Web UI，用来展示监控信息
- 非必需

### 1.2 任务管理器(TaskManager)

Flink集群中的工作进程。通常一个集群中有多个TaskManager运行。

每个TaskManager包含了一定数量的插槽(slots)。**插槽的数量限制了TaskManager能够并行处理的任务数量**

- TaskManager启动后，会向资源管理器注册它的插槽。
- 当收到ResourceManager的指令后，TaskManager就会将一个或者多个slot提供给JobMaster调用。
- JobMaster就可以向插槽分配任务开始执行。

执行过程中，一个TaskManager可以跟其他运行同一应用程序的TaskManager交换数据。

### 1.3 作业提交流程

#### 1.3.1 整体的流程

![image-20220909172142399](/Users/edgar/Documents/www/Flink/markdown-images/image-20220909172142399.png)

#### 1.3.2 Standalone会话模式作业提交流程

![image-20220909172533159](/Users/edgar/Documents/www/Flink/markdown-images/image-20220909172533159.png)

#### 1.3.3 YARN会话模式作业提交流程

![image-20220909172729167](/Users/edgar/Documents/www/Flink/markdown-images/image-20220909172729167.png)

提交任务后，由YARN启动一个TaskManager的容器

#### 1.3.4 YARN单作业模式作业提交流程

![image-20220909172947948](/Users/edgar/Documents/www/Flink/markdown-images/image-20220909172947948.png)

### 1.4 数据流(DataFlow)

应用在JobMaster中会被映射成dataflows，包含了以下三个内容：

- source
- transform
- sink

每个dataflow以一个或者多个sources开始，以一个或者多个sinks结束

### 1.5 并行度(Parallelism)

一个特定算子的子任务(subtask)的个数被称为其并行度

![image-20220914161056738](/Users/edgar/Documents/www/Flink/markdown-images/image-20220914161056738.png)

- 任务并行：后一个算子可能还在算第一份数据时，前一个算子已经在计算第二份数据了
- 数据并行：每一个特定算子可能同时在不同的机器上计算不同的子任务（一般说的并行度就是这个）

**注意：同一个数据流，可能不同的算子有不同的并行度**。因此在代码中可以在算子后面加上.setParallelism(2)将当前算子设置成2个并行度

**<u>设置并行度的优先级</u>**：每个算子的并行度>应用设置的并行度>在提交代码时的命令行中设置的并行度>集群配置文件中的默认并行度

### 1.6 数据传输形式

一个程序中，不同的算子可能有不同的并行度

- One-to-one: 类似spark中的窄依赖。stream维护着分区以及元素的顺序。这意味着map算子的子任务看到的元素的个数以及顺序跟source算子的子任务生产的元素的个数、顺序相同。map、filter、flatMap等算子都是one-to-one的对应关系。
- Redistributing: 类似spark中的宽依赖。stream的分区会发生改变。每个算子的子任务依据所选择的transformation发送数据到不同的目标任务。keyBy基于hashCode重分区，而broadcast和rebalance会随机重新分区。

**算子链(Operator Chains)**合并:相同并行度的one-to-one操作，Flink将这样相连的算子链接在一起形成一个task，原本的算子成为里面的subtask

![image-20220919225301679](/Users/edgar/Documents/www/Flink/markdown-images/image-20220919225301679.png) 

### 1.7 执行图(ExecutionGraph)

Flink中的执行图分为四层：StreamGraph -> JobGraph -> ExecutionGraph -> 物理执行图

- StreamGraph：即DataFlow graph，是根据用户通过Stream API编写的代码生成的最初的图。用来表示程序的拓扑结构。
- JobGraph：StreamGraph经过优化后生成了JobGraph，提交给JobManager的数据结构。主要优化，将多个符合条件的节点chain在一起作为一个节点（即，将多个one-to-one的算子合并成一个任务）
- ExecutionGraph：JobManger根据JobGraph生成ExecutionGraph。ExecutionGraph是JobGraph的并行化版本，**是调度层最核心的数据结构。**
- 物理执行图：JobManager根据ExecutionGraph对Job进行调度后，在各个TaskManager上部署Task后形成的“图”，并不是一个具体的数据结构

![image-20220919233333824](/Users/edgar/Documents/www/Flink/markdown-images/image-20220919233333824.png)

![image-20220919233415273](/Users/edgar/Documents/www/Flink/markdown-images/image-20220919233415273.png)

![image-20220919233501970](/Users/edgar/Documents/www/Flink/markdown-images/image-20220919233501970.png)

### 1.8 任务(Task)和任务槽(Task Slots)

- Task Slot
  - 静态概念，指的是TaskManager具有的并发执行的能力
  - 通过参数taskmanager.numberOfTaskSlots进行配置，推荐cpu核心个数
- 并行度(parallelism)
  - 动态概念，指的是TaskManager运行程序时实际使用的并发能力
  - 通过参数parallelism.default进行配置

![image-20220922214120886](/Users/edgar/Documents/www/Flink/markdown-images/image-20220922214120886.png)

Flink允许子任务共享slot。**因此一个slot可以保证作业的整个管道**

例如，有2个TaskManager，每个TaskManager有3个Task Slot，那么同时可运行6个作业

## 2. DataStream API

DataStream本身是Flink中一个用来表示数据集合的类。通过链式方法对这种数据类型进行处理。这种一连串的操作就叫做**转换(transformations)**

一个Flink程序，其实就是对DataStream的各种转换。

程序一般有以下几部分构成：

- 获取执行环境(execution environment)
- 读取数据源(source)
- 定义基于数据的转换操作(transformations)
- 定义计算结果的输出位置(sink)
- 触发程序执行(execute)

### 2.1 执行环境

#### 2.1.1 创建执行环境

通过StreamExecutionEnvironment类的对象，来获取执行环境。具体方法有以下三种

##### 2.1.1.1 getExecutionEnvironment

通过当前运行的上下文直接获得环境。如果是在本地运行，获得本地执行环境；如果在集群中运行，则获得集群执行环境。

```java
StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
```

##### 2.1.1.2 createLocalEnvironment

返回一个本地执行环境，传入一个参数，指定默认的并行度。如果为空，默认并行度为本地的CPU核心数。

```java
StreamExecutionEnvironment localEnv = StreamExecutionEnvironment.createLocalEnvironment();
```

##### 2.1.1.3 createRemoteEnvironment

返回集群执行环境。需要在调用时制定JobManager的主机名和端口号，并指定要在集群中运行的Jar包。

```java
StreamExecutionEnvironment remoteEnv = StreamExecutionEnvironment.createRemoteEnvironment(
	"host",	// JobManager主机名
	6123,		// JobManager进程端口号
	"path/to/jarFile.jar"	// 提交给JobManager的JAR包
);
```

#### 2.1.2 执行模式(Execution Mode)

##### 2.1.2.1 流执行模式(Streaming)

用于需要持续实时处理的无界数据流。

##### 2.1.2.2 批执行模式(Batch)

用于不需要持续计算的有界数据。

- 通过命令行配置

  仅在提交作业时，增加execution.runtime-mode参数，指定值为BATCH

  ```sh
  bin/flink run -Dexecution.runtime-mode=BATCH ...
  ```

- 通过代码配置

  ```java
  StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
  env.setRuntimeMode(RuntimeExecutionMode.BATCH);
  ```

一般不在代码中配置，而是使用命令行。通过提交作业时的命令来指定参数可以更加灵活。这样同一段代码即可以用于批处理，也可以用于流处理。

##### 2.1.2.3 自动模式(Automatic)

将由程序根据输入数据源是否有界，来自动选择执行模式

#### 2.1.3 触发程序执行

```java
env.execute();
```

Flink是由事件驱动，只有等到数据到来，才会触发真正的计算，所以需要显式地调用执行环境的execute()方法来触发程序执行。

### 2.2 源算子(Source)

